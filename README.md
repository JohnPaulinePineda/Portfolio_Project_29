# [Supervised Learning : Exploring Performance Evaluation Metrics for Survival Prediction](https://johnpaulinepineda.github.io/Portfolio_Project_29/)

[<img src="https://img.shields.io/badge/R-blue?logoColor=blue&labelColor=white&style=for-the-badge" alt="R Badge"/>](https://www.r-project.org/) [<img src="https://img.shields.io/badge/RStudio-blue?logoColor=blue&labelColor=white&style=for-the-badge" alt="RStudio Badge"/>](https://posit.co/downloads/)

This [project](https://johnpaulinepineda.github.io/Portfolio_Project_29/) explores the various performance metrics which are adaptable to censoring conditions for evaluating survival model predictions. Using the Survival Random Forest and Cox Proportional Hazards Regression model structures, metrics applied in the analysis to estimate the generalization performance of survival models on out-of-sample data included the Concordance Index, Brier Score, Integrated Absolute Error and Integrated Square Error. The resulting split-sample cross-validated estimations derived from the metrics were evaluated in terms of their performance consistency across the candidate models. Considering the differences in their intended applications and current data restrictions, a comparison of each metric's strengths and limitations was briefly discussed.

<img src="images/Project29_Summary.png?raw=true"/>
